{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "482080c5",
   "metadata": {},
   "source": [
    "# Popular Tourist Destinations in New Zealand\n",
    "*A Webscrapping Project on Dynamic and Static Webpages*\n",
    "* I Putu Agastya Harta Pratama\n",
    "* Łukasz Brzoska\n",
    "\n",
    "Faculty of Economic Sciences <br>\n",
    "University of Warsaw <br>\n",
    "Warsaw, Poland <br>\n",
    "2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a51b5dc",
   "metadata": {},
   "source": [
    "Data obtained from the New Zealand's government Tourism Board (trading as Tourism New Zealand): https://www.newzealand.com/int/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bd6b92",
   "metadata": {},
   "source": [
    "\n",
    "With so much to offer, traveling to New Zealand may be quite burdensome. The national tourism board of New Zealand has created a website so that prospective tourists may see what the country has to offer. This project aims to informations from the website's top tourist destinations in New Zealand, along with the activities offered there, with the means of webscrapping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0781e0d4",
   "metadata": {},
   "source": [
    "Beautifulsoup and Selenium are both used in this project's scraping process. <br>\n",
    "Selenium is used to automate specific user actions, so that the information may be accessed. <br> \n",
    "The static HTML content that was shown in each page's front end is then scraped using Beautifulsoup. It's also used for collecting links and texts. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34be49b9",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d59db363-b050-4839-b620-897248d7188d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR DATA PROCESSING:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# FOR MEASURING COMPUTATION TIME, CREATING FIXED DELAYS:\n",
    "import time\n",
    "\n",
    "# FOR APPLYING BEAUTIFULSOUP\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# FOR APPLYING SELENIUM:\n",
    "import selenium \n",
    "from selenium import webdriver \n",
    "from webdriver_manager.firefox import GeckoDriverManager \n",
    "from selenium.webdriver.chrome.service import Service \n",
    "from selenium.webdriver.support.ui import WebDriverWait \n",
    "from selenium.webdriver.support import expected_conditions as EC \n",
    "from selenium.webdriver.common.by import By \n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "# FOR SAVING DATA:\n",
    "import pickle # pickle format of saved output\n",
    "\n",
    "# FOR URL PARSING:\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "# FOR SHOWING IMAGES IN THE NOTEBOOK\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908817f5",
   "metadata": {},
   "source": [
    "Once all of the necessary packages has been imported, we will now install the necessary driver. <br>\n",
    "For the purpose of this project, we will be utilising the firefox webbrowser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "998dadb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Driver Installed at:  /Users/agastyaharta/.wdm/drivers/geckodriver/mac64/v0.36.0/geckodriver\n"
     ]
    }
   ],
   "source": [
    "def save_object(obj, filename): \n",
    "    with open(filename, 'wb') as output:\n",
    "        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "firefoxpath = GeckoDriverManager().install(); print(\"Driver Installed at: \", firefoxpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d57fd9a",
   "metadata": {},
   "source": [
    "## Accessing Website"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0413a23d",
   "metadata": {},
   "source": [
    "Firstly, we need to access this site. It leads us to the main page of New Zealand's Tourism page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5121fe1-5bcc-42dd-b787-1f20b4c5c25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "website = \"https://www.newzealand.com/int/\"\n",
    "\n",
    "service_firefox = Service(executable_path = firefoxpath) \n",
    "options_firefox = webdriver.FirefoxOptions()\n",
    "driver_firefox = webdriver.Firefox(service = service_firefox, options = options_firefox) \n",
    "\n",
    "driver_firefox.maximize_window()\n",
    "driver_firefox.get(website)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e709bc28",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "Image(filename='assets/1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d0e887",
   "metadata": {},
   "source": [
    "## Collecting Popular Places "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0564c2",
   "metadata": {},
   "source": [
    "Next, we are acquiring four of New Zealand's most visited destinations, the majority of which are at the city or district level. <br> \n",
    "We are then gathering the city names and links, which is done by licking the search button displayed on the top right corner of this website. <br>\n",
    "BeautifulSoup is used to gather the city names and URLs that are included in the HTML code, and Selenium is used to automate the button clicking. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b47e153d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing website using Selenium\n",
    "driver_firefox.get(website) \n",
    "\n",
    "start = time.time()\n",
    "time.sleep(np.random.chisquare(3)+5) # + wait random time drawn from specific (strongly right-side-skewed) distribution to better imitate human behavior\n",
    "\n",
    "# Clicking the search button to trigger \n",
    "target_button_xpath = \"//i[@class='o-icon js-icon search-icon']//*[@class='icon search']\"\n",
    "target_button = WebDriverWait(driver_firefox, 4).until(\n",
    "    EC.element_to_be_clickable((By.XPATH, target_button_xpath))\n",
    ")\n",
    "target_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4868805e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Popular Places to Visit in New Zealand:\n",
      "Auckland: https://www.newzealand.com/int/utilities/search/?q=Auckland&type=popular\n",
      "Queenstown: https://www.newzealand.com/int/utilities/search/?q=Queenstown&type=popular\n",
      "Lake Tekapo / Takapō: https://www.newzealand.com/int/utilities/search/?q=Lake+Tekapo+%2F+Takap%C5%8D&type=popular\n",
      "Wānaka: https://www.newzealand.com/int/utilities/search/?q=W%C4%81naka&type=popular\n"
     ]
    }
   ],
   "source": [
    "# Using beautifulsoup to generate city labels and their corresponding links\n",
    "html = driver_firefox.page_source # Refering from the website_search variable and converting it to string using page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# Finding the right element for city (\"Popular places to visit\") because they share the same element with (\"Popular things to do\")\n",
    "group_labels = soup.find_all(\"p\", class_=\"popular-searches__group-label\")\n",
    "target_label = None\n",
    "for label in group_labels:\n",
    "    if \"Popular places to visit\" in label.text:\n",
    "        target_label = label\n",
    "        break\n",
    "\n",
    "# Once target label are found, we are extracting each links in corresponds to each city names\n",
    "popular_links = [] # List to save those elements\n",
    "if target_label:\n",
    "    city_list = target_label.find_next_sibling(\"ul\", class_=\"popular-searches__group-items\")\n",
    "    for link in city_list.find_all(\"a\", class_=\"popular-searches__group-item\"):\n",
    "        city_name = link.get_text(strip=True)\n",
    "        href = urljoin(website, link[\"href\"])\n",
    "        popular_links.append((city_name, href))\n",
    "\n",
    "# Printing the output of collected names of popular places (cities) and their corresponding search links\n",
    "try: # Error handling\n",
    "    print(\"Popular Places to Visit in New Zealand:\")\n",
    "    for city, url in popular_links:\n",
    "        print(f\"{city}: {url}\")\n",
    "except Exception as e: # Error handling\n",
    "    print(\"Cannot retrieve data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1482d394",
   "metadata": {},
   "source": [
    "According to this website, in New Zealand there are four of the most visited cities. Our observations indicate that the quantity of activities varies by city. For example, Auckland has 740 listed, whereas Lake Tekapō has 82. We are only gathering 50 activities per city to maintain balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cae3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='assets/2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfcf1e5",
   "metadata": {},
   "source": [
    " Afterwards, we open a new browser tab for each city links that are stored in the popular_links list and stores the unique tab handle in a dictionary called city_tab_handles. By doing this, we can keep multiple city pages open in separate tabs and easily switch between them later using their cleaned-up city names as keys. It allows us to immediately access those city, and keep the scraping process organised across multiple locations without repeatedly closing and reopening browser windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f509474",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_tab_handles = {}\n",
    "\n",
    "for city, url in popular_links:\n",
    "    # Opening new tab\n",
    "    driver_firefox.execute_script(\"window.open();\")\n",
    "    driver_firefox.switch_to.window(driver_firefox.window_handles[-1])\n",
    "    \n",
    "    # Load city URL\n",
    "    driver_firefox.get(url)\n",
    "    time.sleep(5)\n",
    "\n",
    "    # Store tab handle\n",
    "    handle_key = city.lower().replace(\" \", \"_\").replace(\"/\", \"_\")\n",
    "    city_tab_handles[handle_key] = driver_firefox.current_window_handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ddd8df6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auckland': '3afcd02e-d844-415b-b8f0-34b85d40cc24',\n",
       " 'queenstown': 'f25e6575-698b-42b1-85cf-283dd3bef6c6',\n",
       " 'lake_tekapo___takapō': 'aace41ff-5805-4d36-990f-678cd9ff1ee7',\n",
       " 'wānaka': 'e36493b3-7f89-4552-adac-abdad2042f0e'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_tab_handles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c56da7",
   "metadata": {},
   "source": [
    "## Auckland"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6295a36d",
   "metadata": {},
   "source": [
    "We are now switching to the first city within the list. In here we are clicking the activities filter using. Since this website only load 10 results of activities, we have to click the \"Show More Result\" button. To do this, we are using Selenium to automate the button filter clicking, as well as the loading more results. <br>\n",
    "\n",
    "We need to load all of the results that we want to scrape beforehand and then obtaining "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adc3d731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activities' filter clicked on Auckland page.\n"
     ]
    }
   ],
   "source": [
    "# Switching to \"Auckland Tab\"\n",
    "driver_firefox.switch_to.window(city_tab_handles[\"auckland\"])\n",
    "\n",
    "time.sleep(5)\n",
    "# Click on the \"Activities\" filter\n",
    "try:\n",
    "    filter_xpath = \"//span[contains(text(),'Activities')]\"\n",
    "    filter_button = WebDriverWait(driver_firefox, 4).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, filter_xpath))\n",
    "    )\n",
    "    filter_button.click()\n",
    "    print(\"Activities' filter clicked on Auckland page.\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to click 'Activities': {e}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d06372-1dc1-4400-a3cb-59c8086160e6",
   "metadata": {},
   "source": [
    "We decided to scrape 50 activities for each city, but, since there were only 10 activities displayed at once it was required to create a loop that pressed the \"load more\" button to display the next 10 activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "779f9294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading more pages...\n",
      "Loading more pages...\n",
      "Loading more pages...\n",
      "Loading more pages...\n"
     ]
    }
   ],
   "source": [
    "time.sleep(np.random.chisquare(3)+5)\n",
    "# Minimum clicks\n",
    "click = 0 \n",
    "# Maximum clicks (Each page loads 10 results)\n",
    "max_clicks = 4\n",
    "while click < max_clicks:\n",
    "    try:\n",
    "        load_more_xpath = '//*[@id=\"search-results\"]/div[2]/div/div[3]/button'\n",
    "        load_more_button = WebDriverWait(driver_firefox, 5).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, load_more_xpath))\n",
    "        )\n",
    "\n",
    "        # Click the button\n",
    "        load_more_button.click()\n",
    "        click += 1\n",
    "        print(\"Loading more pages...\")\n",
    "\n",
    "        # Waiting content to load\n",
    "        time.sleep(5)\n",
    "\n",
    "    except TimeoutException:\n",
    "        print(\"All pages loaded (no more button).\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64c3212",
   "metadata": {},
   "source": [
    "### Data Scraping for Auckland"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d649d63f-89be-48c6-8f23-d66a37149f1a",
   "metadata": {},
   "source": [
    "Once all of the acrivities were loaded it was time to scrape the data concerning each one of them. By implementing Beautiful Soup we were able to iterate over every single activity in Auckland and gather information about their title, their link, description and image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ca58b5",
   "metadata": {},
   "source": [
    "#### Main Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867c9e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = driver_firefox.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "results_container = soup.find(\"div\", class_=\"search-results__results\")\n",
    "activity_blocks = results_container.find_all(\"div\", class_=\"results__wrapper\") if results_container else []\n",
    "\n",
    "# Saving each columns to list\n",
    "titles_auckland = []\n",
    "links_auckland= []\n",
    "descriptions_auckland = []\n",
    "images_auckland = []\n",
    "\n",
    "\n",
    "for activity in activity_blocks:\n",
    "    try:\n",
    "        # Title\n",
    "        title_path = activity.select_one(\"h4.results__title a\")\n",
    "        title = title_path.get_text(strip=True) if title_path else \"\"\n",
    "        \n",
    "        # Link\n",
    "        link = title_path[\"href\"] if title_path and \"href\" in title_path.attrs else \"\"\n",
    "\n",
    "        # Description\n",
    "        desc_path = activity.select_one(\"p.results__description\")\n",
    "        description = desc_path.get_text(strip=True) if desc_path else \"\"\n",
    "\n",
    "        # Image\n",
    "        img_path = activity.select_one(\"figure.results__photo img\")\n",
    "        img_url = img_path[\"src\"] if img_path and \"src\" in img_path.attrs else \"\"\n",
    "\n",
    "        # Append All\n",
    "        titles_auckland.append(title)\n",
    "        links_auckland.append(link)\n",
    "        descriptions_auckland.append(description)\n",
    "        images_auckland.append(img_url)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping block due to: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06396394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Auckland Scenic Tour 3 Hour',\n",
       " 'Odysseum Auckland',\n",
       " 'Auckland Tours',\n",
       " 'Auckland Museum',\n",
       " 'Breakout Auckland',\n",
       " 'Paintvine - Auckland',\n",
       " 'Skydive Auckland',\n",
       " 'Hello Auckland small-group walking tour | Aucky Walky Tours',\n",
       " 'Auckland City Express - Private Tour (Sedan or Minivan up to 11 passengers)',\n",
       " 'Auckland City Sightseeing Tour',\n",
       " 'Suzannah Maree Photography',\n",
       " 'Auckland Surfboard Rentals',\n",
       " 'Auckland Adventure Jet',\n",
       " 'Auckland Harbour Sailing',\n",
       " 'Auckland Adventure Park',\n",
       " 'Auckland Sunrise Tours',\n",
       " 'Auckland Floral Experiences',\n",
       " 'Zero Latency Auckland',\n",
       " 'Auckland Sea Kayaks',\n",
       " 'Auckland Explorer Bus',\n",
       " 'Adrenalin Forest Auckland',\n",
       " 'Auckland Theatre Company',\n",
       " 'Auckland City Tours',\n",
       " 'Auckland Day Tours',\n",
       " 'Game Over Auckland',\n",
       " 'Auckland Botanic Gardens',\n",
       " 'Sunset Tours Auckland',\n",
       " 'Auckland Motorbike Hire',\n",
       " 'Escape HQ Auckland',\n",
       " 'HireBikes - Auckland Central',\n",
       " 'Aotea Gifts - Auckland',\n",
       " 'Auckland Historic Bar Tour',\n",
       " \"A 'Taste' of the Segway Sensation - A Ride with Magic Broomstick Tours\",\n",
       " 'Scenic Off-Road 4x4 Tours',\n",
       " 'Auckland Private Luxury Tour',\n",
       " 'Power to the Pedal',\n",
       " 'The Ponsonby And K RD Walking Tour',\n",
       " 'Auckland Zoo Te Wao Nui Tour',\n",
       " 'Matakana Art & Wine Escape',\n",
       " 'InterCity Hobbiton Day Tour from Auckland',\n",
       " 'Wings & Waves Ltd',\n",
       " 'Ocean Groove Cruises',\n",
       " 'Auckland to Sanctuary Mountain Private Tour',\n",
       " 'Got To Get Out Paddleboarding',\n",
       " 'Zahn - Auckland Wedding Photographer',\n",
       " 'Miller Road Fragrances - Auckland',\n",
       " 'Sky Tower - SkyCity Auckland',\n",
       " 'Auckland Highlights Luxury Tour',\n",
       " 'GoGuided Auckland Overview Tour',\n",
       " 'Auckland Whale & Dolphin Safari']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles_auckland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9e8a1b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.newzealand.com/int/plan/business/auckland-scenic-tour/',\n",
       " 'https://www.newzealand.com/int/plan/business/odyssey-sensory-maze/',\n",
       " 'https://www.newzealand.com/int/plan/business/auckland-tours/',\n",
       " 'https://www.newzealand.com/int/plan/business/auckland-museum-tamaki-paenga-hira/',\n",
       " 'https://www.newzealand.com/int/plan/business/breakout-auckland/',\n",
       " 'https://www.newzealand.com/int/plan/business/paintvine/',\n",
       " 'https://www.newzealand.com/int/plan/business/skydive-auckland/',\n",
       " 'https://www.newzealand.com/int/plan/business/aucky-walky-tours-ltd/',\n",
       " 'https://www.newzealand.com/int/plan/business/auckland-tour-minivan-up-to-11-passengers/',\n",
       " 'https://www.newzealand.com/int/plan/business/discover-auckland-city-tour-the-city-of-sails/',\n",
       " 'https://www.newzealand.com/int/plan/business/suzannah-maree-photography/',\n",
       " 'https://www.newzealand.com/int/plan/business/auckland-surfboard-rentals/',\n",
       " 'https://www.newzealand.com/int/plan/business/auckland-adventure-jet/',\n",
       " 'https://www.newzealand.com/int/plan/business/harbour-sailing/',\n",
       " 'https://www.newzealand.com/int/plan/business/auckland-adventure-park/',\n",
       " 'https://www.newzealand.com/int/plan/business/auckland-sunrise-tours/',\n",
       " 'https://www.newzealand.com/int/plan/business/auckland-floral-experiences/',\n",
       " 'https://www.newzealand.com/int/plan/business/zero-latency-auckland/',\n",
       " 'https://www.newzealand.com/int/plan/business/auckland-sea-kayaks/',\n",
       " 'https://www.newzealand.com/int/plan/business/auckland-hop-on-hop-off-explorer-1/',\n",
       " 'https://www.newzealand.com/int/plan/business/adrenalin-forest-auckland/',\n",
       " 'https://www.newzealand.com/int/plan/business/auckland-theatre-company/',\n",
       " 'https://www.newzealand.com/int/plan/business/auckland-city-tours/',\n",
       " 'https://www.newzealand.com/int/plan/business/auckland-city-highlights-small-group-tour-/',\n",
       " 'https://www.newzealand.com/int/plan/business/game-over-auckland/',\n",
       " 'https://www.newzealand.com/int/plan/business/auckland-botanic-gardens/',\n",
       " 'https://www.newzealand.com/int/plan/business/sunset-tours-auckland/',\n",
       " 'https://www.newzealand.com/int/plan/business/auckland-motorbike-hire-3933348/',\n",
       " 'https://www.newzealand.com/int/plan/business/escape-hunt-auckland/',\n",
       " 'https://www.newzealand.com/int/plan/business/hirebikes-auckland-central/',\n",
       " 'https://www.newzealand.com/int/plan/business/aotea-souvenirs-auckland/',\n",
       " 'https://www.newzealand.com/int/plan/business/auckland-historic-bar-tour-/',\n",
       " 'https://www.newzealand.com/int/plan/business/a-taste-of-the-mighty-segway-a-ride-with-magic-broomstick-tours/',\n",
       " 'https://www.newzealand.com/int/plan/business/scenic-off-road-4x4-tours/',\n",
       " 'https://www.newzealand.com/int/plan/business/auckland-private-luxury-tours/',\n",
       " 'https://www.newzealand.com/int/plan/business/power-to-the-pedal/',\n",
       " 'https://www.newzealand.com/int/plan/business/the-ponsonby-and-k-rd-walking-tour-/',\n",
       " 'https://www.newzealand.com/int/plan/business/te-wao-nui-the-living-realm-at-auckland-zoo/',\n",
       " 'https://www.newzealand.com/int/plan/business/matakana-art-wine-escape/',\n",
       " 'https://www.newzealand.com/int/plan/business/intercity-hobbiton-day-tour-from-auckland/',\n",
       " 'https://www.newzealand.com/int/plan/business/wings-and-waves-ltd-3127608/',\n",
       " 'https://www.newzealand.com/int/plan/business/ocean-groove-cruises/',\n",
       " 'https://www.newzealand.com/int/plan/business/auckland-to-sanctuary-mountain-and-hobbiton-movie-set-private-tour/',\n",
       " 'https://www.newzealand.com/int/plan/business/got-to-get-out-paddleboarding/',\n",
       " 'https://www.newzealand.com/int/plan/business/zahn-auckland-wedding-photographer/',\n",
       " 'https://www.newzealand.com/int/plan/business/miller-road-fragrance-studio-queenstown/',\n",
       " 'https://www.newzealand.com/int/plan/business/sky-tower-skycity-auckland/',\n",
       " 'https://www.newzealand.com/int/plan/business/auckland-highlights-luxury-tour-including-sky-tower-entry/',\n",
       " 'https://www.newzealand.com/int/plan/business/goguided-auckland-overview-tour/',\n",
       " 'https://www.newzealand.com/int/plan/business/auckland-whale-and-dolphin-safari/']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links_auckland"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3a7d4c",
   "metadata": {},
   "source": [
    "#### Secondary Each Activities Page"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f02f43-b999-4717-88c6-b76d58a6158f",
   "metadata": {},
   "source": [
    "We decided to further broaden the scope of information about every activity and in order to do that we accessed the supbage of every activity that we wanted to scrape. After doing that we were presented with a new page that contained much more specific information such as: address, phone number and email. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b902a50a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sleeping for 6.19 seconds...\n",
      "Sleeping for 4.23 seconds...\n",
      "Sleeping for 8.86 seconds...\n",
      "Sleeping for 10.84 seconds...\n",
      "Sleeping for 7.95 seconds...\n",
      "Sleeping for 5.56 seconds...\n",
      "Sleeping for 8.58 seconds...\n",
      "Sleeping for 6.12 seconds...\n",
      "Sleeping for 7.14 seconds...\n",
      "Sleeping for 5.56 seconds...\n",
      "Sleeping for 8.22 seconds...\n",
      "Sleeping for 4.30 seconds...\n",
      "Sleeping for 6.79 seconds...\n",
      "Sleeping for 5.18 seconds...\n",
      "Sleeping for 8.46 seconds...\n",
      "Sleeping for 5.71 seconds...\n",
      "Sleeping for 6.29 seconds...\n",
      "Sleeping for 7.14 seconds...\n",
      "Sleeping for 5.90 seconds...\n",
      "Sleeping for 6.70 seconds...\n",
      "Sleeping for 7.82 seconds...\n",
      "Sleeping for 10.30 seconds...\n",
      "Sleeping for 9.95 seconds...\n",
      "Sleeping for 6.82 seconds...\n",
      "Sleeping for 11.08 seconds...\n",
      "Sleeping for 5.29 seconds...\n",
      "Sleeping for 5.61 seconds...\n",
      "Sleeping for 12.81 seconds...\n",
      "Sleeping for 4.88 seconds...\n",
      "Sleeping for 15.94 seconds...\n",
      "Sleeping for 8.40 seconds...\n",
      "Sleeping for 13.10 seconds...\n",
      "Sleeping for 4.28 seconds...\n",
      "Sleeping for 4.54 seconds...\n",
      "Sleeping for 6.45 seconds...\n",
      "Sleeping for 6.49 seconds...\n",
      "Sleeping for 5.37 seconds...\n",
      "Sleeping for 14.38 seconds...\n",
      "Sleeping for 13.21 seconds...\n",
      "Sleeping for 4.49 seconds...\n",
      "Sleeping for 6.94 seconds...\n",
      "Sleeping for 6.54 seconds...\n",
      "Sleeping for 6.66 seconds...\n",
      "Sleeping for 4.57 seconds...\n",
      "Sleeping for 14.50 seconds...\n",
      "Sleeping for 5.80 seconds...\n",
      "Sleeping for 9.48 seconds...\n",
      "Sleeping for 11.82 seconds...\n",
      "Sleeping for 7.90 seconds...\n",
      "Sleeping for 8.68 seconds...\n"
     ]
    }
   ],
   "source": [
    "street_addresses_auckland = []\n",
    "localities_auckland = []\n",
    "emails_auckland = []\n",
    "phone_numbers_auckland = []\n",
    "\n",
    "for idx, url in enumerate(links_auckland):\n",
    "    try:\n",
    "        # Open \n",
    "        driver_firefox.get(url)\n",
    "        WebDriverWait(driver_firefox, 5).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \"p[itemtype='http://schema.org/LocalBusiness']\"))\n",
    "        )\n",
    "\n",
    "        detail_soup = BeautifulSoup(driver_firefox.page_source, \"html.parser\")\n",
    "        address_block = detail_soup.select_one(\"p[itemtype='http://schema.org/LocalBusiness']\")\n",
    "\n",
    "        # Street\n",
    "        street_path = address_block.select_one(\"span[itemprop='streetAddress']\")\n",
    "        street_text = street_path.get_text(strip=True) if street_path else \"\"\n",
    "        \n",
    "        # Locality\n",
    "        locality_path = address_block.select_one(\"span[itemprop='addressLocality']\")\n",
    "        locality_text = locality_path.get_text(strip=True) if locality_path else \"\"\n",
    "        \n",
    "        # Phone\n",
    "        phone_path = driver_firefox.find_elements(By.CSS_SELECTOR, \"a.js-phone-link\")\n",
    "        phone_number = phone_path[0].get_attribute(\"href\").replace(\"tel:\", \"\").strip() if phone_path else \"\"\n",
    "        \n",
    "        # Email\n",
    "        email_tag = driver_firefox.find_elements(By.CSS_SELECTOR, \"a[href^='mailto:']\")\n",
    "        email = email_tag[0].get_attribute(\"href\").replace(\"mailto:\", \"\").strip() if email_tag else \"\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"{idx+1}. Failed to extract data for: {links_auckland[idx]} — {e}\")\n",
    "        street_text = \"\"\n",
    "        locality_text = \"\"\n",
    "\n",
    "    street_addresses_auckland.append(street_text)\n",
    "    localities_auckland.append(locality_text)\n",
    "    emails_auckland.append(email)\n",
    "    phone_numbers_auckland.append(phone_number)\n",
    "    \n",
    "    # Wait time to avoid being blocked\n",
    "    wait_time = np.random.chisquare(3) + 4\n",
    "    print(f\"Sleeping for {wait_time:.2f} seconds...\")\n",
    "    time.sleep(wait_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795360de",
   "metadata": {},
   "source": [
    "### Final Check of Auckland Scrapped Lists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1deb68b-f01a-4a84-a75c-b9c4e4757c42",
   "metadata": {},
   "source": [
    "The results of scraping activities in Auckland are presented below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42c45dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "auckland_scrapped_lists = [\n",
    "    titles_auckland,\n",
    "    links_auckland,\n",
    "    descriptions_auckland,\n",
    "    images_auckland,\n",
    "    street_addresses_auckland,\n",
    "    localities_auckland,\n",
    "    emails_auckland,\n",
    "    phone_numbers_auckland,\n",
    "]\n",
    "\n",
    "list_names = [\n",
    "    \"titles_auckland\",\n",
    "    \"links_auckland\",\n",
    "    \"descriptions_auckland\",\n",
    "    \"images_auckland\",\n",
    "    \"street_addresses_auckland\",\n",
    "    \"localities_auckland\",\n",
    "    \"emails_auckland\",\n",
    "    \"phone_numbers_auckland\",\n",
    "]\n",
    "\n",
    "for i, name in enumerate(auckland_scrapped_lists):\n",
    "    print(f\"List length of {list_names[i]}: {len(name)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d46cd02-50f2-428b-9d7a-315ab55d6d0b",
   "metadata": {},
   "source": [
    "The exact same process was repeated for the remaining cities of Queenstown, Lake Tekapo and Wanaka. Since each city had their own page with availible activities, we created seperate datasets for all of them which we then connected into a dataframe containing full information about all cities.\n",
    "\n",
    "\n",
    "Below we present the processess of scraping the remaining cities:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9be5658",
   "metadata": {},
   "source": [
    "## Queenstown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568b6953",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_firefox.switch_to.window(city_tab_handles[\"queenstown\"])\n",
    "\n",
    "time.sleep(5)\n",
    "# Click on the \"Activities\" filter\n",
    "try:\n",
    "    filter_xpath = \"//span[contains(text(),'Activities')]\"\n",
    "    filter_button = WebDriverWait(driver_firefox, 4).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, filter_xpath))\n",
    "    )\n",
    "    filter_button.click()\n",
    "    print(\"Activities' filter clicked on Queenstown page.\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to click 'Activities': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94096a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(np.random.chisquare(3)+5)\n",
    "click = 0 \n",
    "max_clicks = 4\n",
    "while click < max_clicks:\n",
    "    try:\n",
    "        load_more_xpath = '//*[@id=\"search-results\"]/div[2]/div/div[3]/button'\n",
    "        load_more_button = WebDriverWait(driver_firefox, 5).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, load_more_xpath))\n",
    "        )\n",
    "\n",
    "        # Click the button\n",
    "        load_more_button.click()\n",
    "        click += 1\n",
    "        print(\"Loading more...\")\n",
    "\n",
    "        # Optional: wait for new content to load\n",
    "        time.sleep(5)\n",
    "\n",
    "    except TimeoutException:\n",
    "        print(\"All activities loaded (no more button).\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b5a9be",
   "metadata": {},
   "source": [
    "### Data Scraping for Queenstown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf04ff5c",
   "metadata": {},
   "source": [
    "#### Main Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cb10ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = driver_firefox.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "results_container = soup.find(\"div\", class_=\"search-results__results\")\n",
    "activity_blocks = results_container.find_all(\"div\", class_=\"results__wrapper\") if results_container else []\n",
    "\n",
    "titles_queenstown = []\n",
    "links_queenstown= []\n",
    "descriptions_queenstown = []\n",
    "images_queenstown = []\n",
    "\n",
    "for activity in activity_blocks:\n",
    "    try:\n",
    "        # Title\n",
    "        title_path = activity.select_one(\"h4.results__title a\")\n",
    "        title = title_path.get_text(strip=True) if title_path else \"\"\n",
    "        \n",
    "        # Link\n",
    "        link = title_path[\"href\"] if title_path and \"href\" in title_path.attrs else \"\"\n",
    "\n",
    "        # Description\n",
    "        desc_path = activity.select_one(\"p.results__description\")\n",
    "        description = desc_path.get_text(strip=True) if desc_path else \"\"\n",
    "\n",
    "        # Image\n",
    "        img_path = activity.select_one(\"figure.results__photo img\")\n",
    "        img_url = img_path[\"src\"] if img_path and \"src\" in img_path.attrs else \"\"\n",
    "\n",
    "        # Append All\n",
    "        titles_queenstown.append(title)\n",
    "        links_queenstown.append(link)\n",
    "        descriptions_queenstown.append(description)\n",
    "        images_queenstown.append(img_url)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping block due to: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe34720",
   "metadata": {},
   "source": [
    "#### Secondary Each Activities Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f149e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "street_addresses_queenstown = []\n",
    "localities_queenstown = []\n",
    "emails_queenstown = []\n",
    "phone_numbers_queenstown = []\n",
    "\n",
    "for idx, url in enumerate(links_queenstown):\n",
    "    try:\n",
    "        driver_firefox.get(url)\n",
    "        WebDriverWait(driver_firefox, 5).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \"p[itemtype='http://schema.org/LocalBusiness']\"))\n",
    "        )\n",
    "\n",
    "        detail_soup = BeautifulSoup(driver_firefox.page_source, \"html.parser\")\n",
    "        address_block = detail_soup.select_one(\"p[itemtype='http://schema.org/LocalBusiness']\")\n",
    "\n",
    "        # Street\n",
    "        street_path = address_block.select_one(\"span[itemprop='streetAddress']\")\n",
    "        street_text = street_path.get_text(strip=True) if street_path else \"\"\n",
    "        \n",
    "        # Locality\n",
    "        locality_path = address_block.select_one(\"span[itemprop='addressLocality']\")\n",
    "        locality_text = locality_path.get_text(strip=True) if locality_path else \"\"\n",
    "        \n",
    "        # Phone\n",
    "        phone_path = driver_firefox.find_elements(By.CSS_SELECTOR, \"a.js-phone-link\")\n",
    "        phone_number = phone_path[0].get_attribute(\"href\").replace(\"tel:\", \"\").strip() if phone_path else \"\"\n",
    "        \n",
    "        # Email\n",
    "        email_tag = driver_firefox.find_elements(By.CSS_SELECTOR, \"a[href^='mailto:']\")\n",
    "        email = email_tag[0].get_attribute(\"href\").replace(\"mailto:\", \"\").strip() if email_tag else \"\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"{idx+1}. Failed to extract data for: {links_queenstown[idx]} — {e}\")\n",
    "        street_text = \"\"\n",
    "        locality_text = \"\"\n",
    "\n",
    "    street_addresses_queenstown.append(street_text)\n",
    "    localities_queenstown.append(locality_text)\n",
    "    emails_queenstown.append(email)\n",
    "    phone_numbers_queenstown.append(phone_number)\n",
    "    \n",
    "    wait_time = np.random.chisquare(3) + 4\n",
    "    print(f\"Sleeping for {wait_time:.2f} seconds...\")\n",
    "    time.sleep(wait_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f17934e",
   "metadata": {},
   "source": [
    "### Final Check of Queenstown Scrapped Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62839a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "queenstown_scrapped_lists = [\n",
    "    titles_queenstown,\n",
    "    links_queenstown,\n",
    "    descriptions_queenstown,\n",
    "    images_queenstown,\n",
    "    street_addresses_queenstown,\n",
    "    localities_queenstown,\n",
    "    emails_queenstown,\n",
    "    phone_numbers_queenstown,\n",
    "]\n",
    "\n",
    "list_names = [\n",
    "    \"titles_queenstown\",\n",
    "    \"links_queenstown\",\n",
    "    \"descriptions_queenstown\",\n",
    "    \"images_queenstown\",\n",
    "    \"street_addresses_queenstown\",\n",
    "    \"localities_queenstown\",\n",
    "    \"emails_queenstown\",\n",
    "    \"phone_numbers_queenstown\",\n",
    "]\n",
    "\n",
    "for i, name in enumerate(queenstown_scrapped_lists):\n",
    "    print(f\"List length of {list_names[i]}: {len(name)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdbfb77",
   "metadata": {},
   "source": [
    "## Lake Tekapo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c6c3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_firefox.switch_to.window(city_tab_handles[\"lake_tekapo___takapō\"])\n",
    "\n",
    "time.sleep(5)\n",
    "# Click on the \"Activities\" filter\n",
    "try:\n",
    "    filter_xpath = \"//span[contains(text(),'Activities')]\"\n",
    "    filter_button = WebDriverWait(driver_firefox, 4).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, filter_xpath))\n",
    "    )\n",
    "    filter_button.click()\n",
    "    print(\"Activities' filter clicked on Lake Tekapo / Takapō page.\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to click 'Activities': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfcd3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(np.random.chisquare(3)+5)\n",
    "click = 0 \n",
    "max_clicks = 4\n",
    "while click < max_clicks:\n",
    "    try:\n",
    "        load_more_xpath = '//*[@id=\"search-results\"]/div[2]/div/div[3]/button'\n",
    "        load_more_button = WebDriverWait(driver_firefox, 5).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, load_more_xpath))\n",
    "        )\n",
    "\n",
    "        # Click the button\n",
    "        load_more_button.click()\n",
    "        click += 1\n",
    "        print(\"Loading more...\")\n",
    "\n",
    "        # Optional: wait for new content to load\n",
    "        time.sleep(5)\n",
    "\n",
    "    except TimeoutException:\n",
    "        print(\"All activities loaded (no more button).\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1895d181",
   "metadata": {},
   "source": [
    "### Data Scraping - Lake Tekapo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db7411d",
   "metadata": {},
   "source": [
    "#### Main Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a97886",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = driver_firefox.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "results_container = soup.find(\"div\", class_=\"search-results__results\")\n",
    "activity_blocks = results_container.find_all(\"div\", class_=\"results__wrapper\") if results_container else []\n",
    "\n",
    "titles_tekapo = []\n",
    "links_tekapo= []\n",
    "descriptions_tekapo = []\n",
    "images_tekapo = []\n",
    "\n",
    "for activity in activity_blocks:\n",
    "    try:\n",
    "        # Title\n",
    "        title_path = activity.select_one(\"h4.results__title a\")\n",
    "        title = title_path.get_text(strip=True) if title_path else \"\"\n",
    "        \n",
    "        # Link\n",
    "        link = title_path[\"href\"] if title_path and \"href\" in title_path.attrs else \"\"\n",
    "\n",
    "        # Description\n",
    "        desc_path = activity.select_one(\"p.results__description\")\n",
    "        description = desc_path.get_text(strip=True) if desc_path else \"\"\n",
    "\n",
    "        # Image\n",
    "        img_path = activity.select_one(\"figure.results__photo img\")\n",
    "        img_url = img_path[\"src\"] if img_path and \"src\" in img_path.attrs else \"\"\n",
    "\n",
    "        # Append All\n",
    "        titles_tekapo.append(title)\n",
    "        links_tekapo.append(link)\n",
    "        descriptions_tekapo.append(description)\n",
    "        images_tekapo.append(img_url)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping block due to: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada1e642",
   "metadata": {},
   "source": [
    "#### Secondary Each Activities Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ab571c",
   "metadata": {},
   "outputs": [],
   "source": [
    "street_addresses_tekapo = []\n",
    "localities_tekapo = []\n",
    "emails_tekapo = []\n",
    "phone_numbers_tekapo = []\n",
    "\n",
    "for idx, url in enumerate(links_tekapo):\n",
    "    try:\n",
    "        driver_firefox.get(url)\n",
    "        WebDriverWait(driver_firefox, 5).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \"p[itemtype='http://schema.org/LocalBusiness']\"))\n",
    "        )\n",
    "\n",
    "        detail_soup = BeautifulSoup(driver_firefox.page_source, \"html.parser\")\n",
    "        address_block = detail_soup.select_one(\"p[itemtype='http://schema.org/LocalBusiness']\")\n",
    "\n",
    "        # Street\n",
    "        street_path = address_block.select_one(\"span[itemprop='streetAddress']\")\n",
    "        street_text = street_path.get_text(strip=True) if street_path else \"\"\n",
    "        \n",
    "        # Locality\n",
    "        locality_path = address_block.select_one(\"span[itemprop='addressLocality']\")\n",
    "        locality_text = locality_path.get_text(strip=True) if locality_path else \"\"\n",
    "        \n",
    "        # Phone\n",
    "        phone_path = driver_firefox.find_elements(By.CSS_SELECTOR, \"a.js-phone-link\")\n",
    "        phone_number = phone_path[0].get_attribute(\"href\").replace(\"tel:\", \"\").strip() if phone_path else \"\"\n",
    "        \n",
    "        # Email\n",
    "        email_tag = driver_firefox.find_elements(By.CSS_SELECTOR, \"a[href^='mailto:']\")\n",
    "        email = email_tag[0].get_attribute(\"href\").replace(\"mailto:\", \"\").strip() if email_tag else \"\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"{idx+1}. Failed to extract data for: {links_tekapo[idx]} — {e}\")\n",
    "        street_text = \"\"\n",
    "        locality_text = \"\"\n",
    "\n",
    "    street_addresses_tekapo.append(street_text)\n",
    "    localities_tekapo.append(locality_text)\n",
    "    emails_tekapo.append(email)\n",
    "    phone_numbers_tekapo.append(phone_number)\n",
    "    \n",
    "    wait_time = np.random.chisquare(3) + 4\n",
    "    print(f\"Sleeping for {wait_time:.2f} seconds...\")\n",
    "    time.sleep(wait_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a030b3f",
   "metadata": {},
   "source": [
    "### Final Check of Lake Tekapo Scrapped Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c669c1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tekapo_scrapped_lists = [\n",
    "    titles_tekapo,\n",
    "    links_tekapo,\n",
    "    descriptions_tekapo,\n",
    "    images_tekapo,\n",
    "    street_addresses_tekapo,\n",
    "    localities_tekapo,\n",
    "    emails_tekapo,\n",
    "    phone_numbers_tekapo,\n",
    "]\n",
    "\n",
    "list_names = [\n",
    "    \"titles_tekapo\",\n",
    "    \"links_tekapo\",\n",
    "    \"descriptions_tekapo\",\n",
    "    \"images_tekapo\",\n",
    "    \"street_addresses_tekapo\",\n",
    "    \"localities_tekapo\",\n",
    "    \"emails_tekapo\",\n",
    "    \"phone_numbers_tekapo\",\n",
    "]\n",
    "\n",
    "for i, name in enumerate(tekapo_scrapped_lists):\n",
    "    print(f\"List length of {list_names[i]}: {len(name)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488754ab",
   "metadata": {},
   "source": [
    "## Wanaka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5703d375",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_firefox.switch_to.window(city_tab_handles[\"wānaka\"])\n",
    "\n",
    "time.sleep(5)\n",
    "# Click on the \"Activities\" filter\n",
    "try:\n",
    "    filter_xpath = \"//span[contains(text(),'Activities')]\"\n",
    "    filter_button = WebDriverWait(driver_firefox, 4).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, filter_xpath))\n",
    "    )\n",
    "    filter_button.click()\n",
    "    print(\"Activities' filter clicked on Wanaka page.\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to click 'Activities': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7b7f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(np.random.chisquare(3)+5)\n",
    "click = 0 \n",
    "max_clicks = 4\n",
    "while click < max_clicks:\n",
    "    try:\n",
    "        load_more_xpath = '//*[@id=\"search-results\"]/div[2]/div/div[3]/button'\n",
    "        load_more_button = WebDriverWait(driver_firefox, 5).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, load_more_xpath))\n",
    "        )\n",
    "\n",
    "        # Click the button\n",
    "        load_more_button.click()\n",
    "        click += 1\n",
    "        print(\"Loading more...\")\n",
    "\n",
    "        # Optional: wait for new content to load\n",
    "        time.sleep(5)\n",
    "\n",
    "    except TimeoutException:\n",
    "        print(\"All activities loaded (no more button).\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59169ee",
   "metadata": {},
   "source": [
    "### Data Scraping - Wanaka"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a94b970",
   "metadata": {},
   "source": [
    "#### Main Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8f8eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = driver_firefox.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "results_container = soup.find(\"div\", class_=\"search-results__results\")\n",
    "activity_blocks = results_container.find_all(\"div\", class_=\"results__wrapper\") if results_container else []\n",
    "\n",
    "titles_wanaka = []\n",
    "links_wanaka= []\n",
    "descriptions_wanaka = []\n",
    "images_wanaka = []\n",
    "\n",
    "for activity in activity_blocks:\n",
    "    try:\n",
    "        # Title\n",
    "        title_path = activity.select_one(\"h4.results__title a\")\n",
    "        title = title_path.get_text(strip=True) if title_path else \"\"\n",
    "        \n",
    "        # Link\n",
    "        link = title_path[\"href\"] if title_path and \"href\" in title_path.attrs else \"\"\n",
    "\n",
    "        # Description\n",
    "        desc_path = activity.select_one(\"p.results__description\")\n",
    "        description = desc_path.get_text(strip=True) if desc_path else \"\"\n",
    "\n",
    "        # Image\n",
    "        img_path = activity.select_one(\"figure.results__photo img\")\n",
    "        img_url = img_path[\"src\"] if img_path and \"src\" in img_path.attrs else \"\"\n",
    "\n",
    "        # Append All\n",
    "        titles_wanaka.append(title)\n",
    "        links_wanaka.append(link)\n",
    "        descriptions_wanaka.append(description)\n",
    "        images_wanaka.append(img_url)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping block due to: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68470f0",
   "metadata": {},
   "source": [
    "#### Secondary Each Activities Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b75bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "street_addresses_wanaka = []\n",
    "localities_wanaka = []\n",
    "emails_wanaka = []\n",
    "phone_numbers_wanaka = []\n",
    "\n",
    "for idx, url in enumerate(links_wanaka):\n",
    "    try:\n",
    "        driver_firefox.get(url)\n",
    "        WebDriverWait(driver_firefox, 5).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \"p[itemtype='http://schema.org/LocalBusiness']\"))\n",
    "        )\n",
    "\n",
    "        detail_soup = BeautifulSoup(driver_firefox.page_source, \"html.parser\")\n",
    "        address_block = detail_soup.select_one(\"p[itemtype='http://schema.org/LocalBusiness']\")\n",
    "\n",
    "        # Street\n",
    "        street_path = address_block.select_one(\"span[itemprop='streetAddress']\")\n",
    "        street_text = street_path.get_text(strip=True) if street_path else \"\"\n",
    "        \n",
    "        # Locality\n",
    "        locality_path = address_block.select_one(\"span[itemprop='addressLocality']\")\n",
    "        locality_text = locality_path.get_text(strip=True) if locality_path else \"\"\n",
    "        \n",
    "        # Phone\n",
    "        phone_path = driver_firefox.find_elements(By.CSS_SELECTOR, \"a.js-phone-link\")\n",
    "        phone_number = phone_path[0].get_attribute(\"href\").replace(\"tel:\", \"\").strip() if phone_path else \"\"\n",
    "        \n",
    "        # Email\n",
    "        email_tag = driver_firefox.find_elements(By.CSS_SELECTOR, \"a[href^='mailto:']\")\n",
    "        email = email_tag[0].get_attribute(\"href\").replace(\"mailto:\", \"\").strip() if email_tag else \"\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"{idx+1}. Failed to extract data for: {links_wanaka[idx]} — {e}\")\n",
    "        street_text = \"\"\n",
    "        locality_text = \"\"\n",
    "\n",
    "    street_addresses_wanaka.append(street_text)\n",
    "    localities_wanaka.append(locality_text)\n",
    "    emails_wanaka.append(email)\n",
    "    phone_numbers_wanaka.append(phone_number)\n",
    "    \n",
    "    wait_time = np.random.chisquare(3) + 4\n",
    "    print(f\"Sleeping for {wait_time:.2f} seconds...\")\n",
    "    time.sleep(wait_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ce57e7",
   "metadata": {},
   "source": [
    "### Final Check of Wanaka Scrapped Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7658d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "wanaka_scrapped_lists = [\n",
    "    titles_wanaka,\n",
    "    links_wanaka,\n",
    "    descriptions_wanaka,\n",
    "    images_wanaka,\n",
    "    street_addresses_wanaka,\n",
    "    localities_wanaka,\n",
    "    emails_wanaka,\n",
    "    phone_numbers_wanaka,\n",
    "]\n",
    "\n",
    "list_names = [\n",
    "    \"titles_wanaka\",\n",
    "    \"links_wanaka\",\n",
    "    \"descriptions_wanaka\",\n",
    "    \"images_wanaka\",\n",
    "    \"street_addresses_wanaka\",\n",
    "    \"localities_wanaka\",\n",
    "    \"emails_wanaka\",\n",
    "    \"phone_numbers_wanaka\",\n",
    "]\n",
    "\n",
    "for i, name in enumerate(wanaka_scrapped_lists):\n",
    "    print(f\"List length of {list_names[i]}: {len(name)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492d07f6",
   "metadata": {},
   "source": [
    "## Convert to Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6166f29-52f6-4ff4-bf7c-0688d258a18b",
   "metadata": {},
   "source": [
    "The last step of the project was to combine all datasets into a single dataframe:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483b99d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_auckland = pd.DataFrame({\n",
    "    \"place\": [\"Auckland\"] * len(titles_auckland),\n",
    "    \"activities\": titles_auckland,\n",
    "    \"activity_descriptions\": descriptions_auckland,\n",
    "    \"activity_address_streets\": street_addresses_auckland,\n",
    "    \"activity_localities\": localities_auckland,\n",
    "    \"activity_emails\": emails_auckland,\n",
    "    \"activity_phone_numbers\": phone_numbers_auckland,\n",
    "    \"activity_links\": links_auckland,\n",
    "    \"activity_images\" : images_auckland\n",
    "})\n",
    "\n",
    "\n",
    "data_queenstown = pd.DataFrame({\n",
    "    \"place\": [\"Queenstown\"] * len(titles_queenstown),\n",
    "    \"activities\": titles_queenstown,\n",
    "    \"activity_descriptions\": descriptions_queenstown,\n",
    "    \"activity_address_streets\": street_addresses_queenstown,\n",
    "    \"activity_localities\": localities_queenstown,\n",
    "    \"activity_emails\": emails_queenstown,\n",
    "    \"activity_phone_numbers\": phone_numbers_queenstown,\n",
    "    \"activity_links\": links_queenstown,\n",
    "    \"activity_images\" : images_queenstown\n",
    "})\n",
    "\n",
    "data_tekapo = pd.DataFrame({\n",
    "    \"place\": [\"Tekapo\"] * len(titles_tekapo),\n",
    "    \"activities\": titles_tekapo,\n",
    "    \"activity_descriptions\": descriptions_tekapo,\n",
    "    \"activity_address_streets\": street_addresses_tekapo,\n",
    "    \"activity_localities\": localities_tekapo,\n",
    "    \"activity_emails\": emails_tekapo,\n",
    "    \"activity_phone_numbers\": phone_numbers_tekapo,\n",
    "    \"activity_links\": links_tekapo,\n",
    "    \"activity_images\" : images_tekapo\n",
    "})\n",
    "\n",
    "data_wanaka = pd.DataFrame({\n",
    "    \"place\": [\"Wanaka\"] * len(titles_wanaka),\n",
    "    \"activities\": titles_wanaka,\n",
    "    \"activity_descriptions\": descriptions_wanaka,\n",
    "    \"activity_address_streets\": street_addresses_wanaka,\n",
    "    \"activity_localities\": localities_wanaka,\n",
    "    \"activity_emails\": emails_wanaka,\n",
    "    \"activity_phone_numbers\": phone_numbers_wanaka,\n",
    "    \"activity_links\": links_wanaka,\n",
    "    \"activity_images\" : images_wanaka\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5ae065",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_auckland.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbcf1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_queenstown.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d16c396",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tekapo.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68061aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_wanaka.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7591f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all_city = []\n",
    "\n",
    "data_all_city.append(data_auckland)\n",
    "data_all_city.append(data_queenstown)\n",
    "data_all_city.append(data_tekapo)\n",
    "data_all_city.append(data_wanaka)\n",
    "\n",
    "final_data = pd.concat(data_all_city, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa29896",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2525ce3a",
   "metadata": {},
   "source": [
    "## Export to Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22419a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.to_pickle(\"pickle_dump/all_city_activities.pkl\")\n",
    "data_auckland.to_pickle(\"pickle_dump/auckland_city_activities.pkl\")\n",
    "data_queenstown.to_pickle(\"pickle_dump/queenstown_city_activities.pkl\")\n",
    "data_tekapo.to_pickle(\"pickle_dump/tekapo_city_activities.pkl\")\n",
    "data_wanaka.to_pickle(\"pickle_dump/wanaka_city_activities.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a222bf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_firefox.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352f87c8",
   "metadata": {},
   "source": [
    "## Mitigation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dea2f4",
   "metadata": {},
   "source": [
    "### Rotation of User Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf1b747",
   "metadata": {},
   "outputs": [],
   "source": [
    "#service_firefox = Service(executable_path = firefoxpath) \n",
    "#options_firefox = webdriver.FirefoxOptions(); options_firefox.add_argument(\"--headless\")\n",
    "#driver_firefox = webdriver.Firefox(service = service_firefox, options = options_firefox)\n",
    "\n",
    "#driver_firefox.get(\"https://us.cnn.com/\")\n",
    "\n",
    "# returns our current User-Agent\n",
    "#user_agent = driver_firefox.execute_script(\"return navigator.userAgent;\")\n",
    "#print(\"Current User-Agent:\", user_agent)\n",
    "\n",
    "#driver_firefox.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e94b5aa",
   "metadata": {},
   "source": [
    "### Rotation of IP Addresses"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
